{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle CAN analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectives\n",
    "Dynamical systems model the complex relationships between quantities that evolve over time. \n",
    "Formally, dynamical systems analyze, predict, and interpret systems of differential equations or iterative mappings that describe the state development of a system. This formulation covers a wide range of phenomena in classical mechanical systems, electrical circuits, turbulent fluids, climate science, finance, ecology, social systems, neuroscience, epidemiology, and nearly every other system that evolves over time.\n",
    "\n",
    "Poincare's work on planets' chaotic motion started modern dynamical systems. It is based on classical mechanics and represents centuries of mathematical modeling, starting with Newton and Leibniz. Dynamical systems have fascinated brilliant brains for millennia and been applied to various fields and difficult issues. Dynamical systems connects linear algebra, differential equations, topology, numerical analysis, and geometry. Nearly all technical, physical, and life sciences use dynamical systems to model and analyze systems.\n",
    "\n",
    "Classical controls and dynamics systems are expressed in terms:\n",
    "\\begin{equation*}\n",
    "   \t\\dot{x} = Ax+Bu,\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\ty= Cx\n",
    "\\end{equation*}\n",
    "\n",
    "where:\n",
    "* X: a state vector or state variable of the system. It typically represents the internal state or variables of a dynamic system that evolves over time.\n",
    "* X_dot: The derivative of the state vector X with respect to time, indicating how the state variables change over time.\n",
    "* A: A matrix that describes the dynamics or evolution of the state variables. It defines how the state variables interact and change over time in the absence of any inputs or disturbances.\n",
    "* B: A matrix that represents the control input vector or the effect of external inputs on the state variables. It shows how the system responds to control inputs or external influences.\n",
    "* u: The control input vector or the input applied to the system to affect its behavior or state evolution. It can be considered as the driving force or external signal acting on the system.\n",
    "* y: The output vector that represents the measurable or observable variables of the system. It is derived from the state variables or directly observed from the system.\n",
    "* C: A matrix that relates the state variables to the output variables. It defines how the state variables contribute to the output measurements or observations.\n",
    "\n",
    "Data-driven techniques are replacing analytical derivations and first principles models in dynamical systems. Big data and machine learning are changing how scientists and engineers analyze dynamical systems. Climate science, finance, epidemiology, and neuroscience problems have ample data but no controlling equations. Researchers are increasingly using data-driven analysis in classical domains like optics and turbulence, where governing equations exist. \n",
    "\n",
    "The Machine Learning techniques provide a new set of tools that can help to understand the system dynamics, thus enabling developing the controls systems without **without knowing the full system dynamics**.\n",
    "\n",
    "In this exercise, I'd like to experiment the modern data-driven controls and dynamical systems approach **without knowing the full system dynamics**.\n",
    "1. Using Regression technique, we can predict the desired outputs Y (i.e, Vehicle Speed) \n",
    "2. Using Classifiers, we can predict the control inputs U (i,e. Brake Voltage)\n",
    "3. Using Time Series anomaly detection to predictively maintain the system\n",
    "\n",
    "References: http://databookuw.com/databook.pdf "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "\n",
    "The dataset is the Vehicle CAN data that is collected directly from the CAN bus inside vehicles, representing the measurements y and inputs u in the system.\n",
    "\n",
    "The dataset contains 20Hz sampled CAN bus data from a passenger vehicle, e.g. \n",
    "* WheelSpeed FL (speed of the front left wheel), \n",
    "* SteerAngle (steering wheel angle), \n",
    "* Role, Pitch, and accelerometer values per direction.\n",
    "\n",
    "Unfortunately, not much further details on the measurement units or how they were collected are given.\n",
    "\n",
    "In contrast to the dataset published at https://zenodo.org/record/2658168#.XMw2m6JS9PY we now have GPS data from the vehicle (see signals 'Latitude_Vehicle' and 'Longitude_Vehicle' in h5 group 'Math') and GPS data from the IMU device (see signals 'Latitude_IMU', 'Longitude_IMU' and 'Time_IMU' in h5 group 'Math') included. However, as it was exported with single_precision, therefore we lost some precision for those GPS values.\n",
    "\n",
    "References: https://zenodo.org/record/2661316 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py # to read the hdf file\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "import time\n",
    "import warnings\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vehicle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_1 = h5py.File('20181116_Driver1_Trip3.hdf', 'r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both files contain multiple subgroups of data, one of which is the aformentioned CAN bus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(driver_1.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn time series data into tables\n",
    "\n",
    "The CAN bus data comes in serialized form - written out in series in a nested format.\n",
    "\n",
    "To handle the CAN bus data more efficiently we'll turn it into tables that are easier to inspect and handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_driver_1 = {}\n",
    "\n",
    "for channel_name, channel_data in driver_1['CAN'].items():\n",
    "  data_driver_1[channel_name] = channel_data[:, 0]\n",
    "\n",
    "df_raw = pd.DataFrame(\n",
    "    data=data_driver_1,\n",
    "    index=channel_data[:, 1]\n",
    ")\n",
    "df_raw = df_raw.loc[:, df_raw.nunique() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tabular data for driver 1 looks as follows - it holds 30746 measured time points in 23 channels that we deem relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "* User Controls Inputs\n",
    "  * AccPedal\n",
    "  * BrkVoltage\n",
    "  * SteerAngle1\n",
    "* Measurements\n",
    "  * AmbientTemperature\n",
    "  * BoostPressure\n",
    "  * ENG_Trq_DMD\n",
    "  * ENG_Trq_ZWR\n",
    "  * ENG_Trq_m_ex\n",
    "  * EngineSpeed_CAN\n",
    "  * EngineTemperature\n",
    "  * Engine_02_BZ\n",
    "  * Engine_02_CHK\n",
    "  * OilTemperature1\n",
    "  * SCS_01_BZ\n",
    "  * SCS_01_CHK\n",
    "  * Trq_FrictionLoss\n",
    "  * Trq_Indicated\n",
    "  * WheelSpeed_FL\n",
    "  * WheelSpeed_FR\n",
    "  * WheelSpeed_RL\n",
    "  * WheelSpeed_RR\n",
    "  * Yawrate1\n",
    "* Vehicle Output under controls\n",
    "  * VehicleSpeed\n",
    "  * SteerAngle1\n",
    "\n",
    "Some of the abbreviations are not fully understanding due to lack of information. We could gather them via contacting the source of the data. However it should not block the progress here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sanity_check(df):\n",
    "    #print(df.describe())\n",
    "    print('===Null values per columns: ')\n",
    "    print(df.isnull().sum())\n",
    "    print(f'===Duplicates found: {df.duplicated().sum()}')\n",
    "    df = df.drop_duplicates()\n",
    "    print(f'===Duplicates removed. Duplicates found: {df.duplicated().sum()}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = data_sanity_check(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore unique data in columns\n",
    "df_unique = df_raw.nunique().to_frame().reset_index()\n",
    "df_unique.columns = ['Variable','Unique counts']\n",
    "print(df_unique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize numeric data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This line is only for exploratory, since it is time consuming to execute. It is good to run it once to give us an idea how the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_raw, title='time series of Vehicle CAN data')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The EngineSpeed_CAN skews the data scale. Lets normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_raw)\n",
    "scaled_df_raw = pd.DataFrame(scaled_data,\n",
    "                         columns=df_raw.columns)\n",
    "scaled_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(scaled_df_raw, title='Time series of Vehicle CAN data')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** \\\n",
    "The data looks very noisy, need to drop some noisy data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_raw.columns\n",
    "## Drop noisy data columns\n",
    "scaled_df1 = scaled_df_raw.drop(columns=['SCS_01_BZ', 'SCS_01_CHK', 'Engine_02_BZ', 'Engine_02_CHK'], axis=1)\n",
    "df1 = df_raw.drop(columns=['SCS_01_BZ', 'SCS_01_CHK', 'Engine_02_BZ', 'Engine_02_CHK'], axis=1)\n",
    "fig = px.line(scaled_df1, title='Time series of Vehicle CAN data, take-1 clean')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** \\\n",
    "The data looks much better and less noisy!\n",
    "\n",
    "Let's examine some critical info of the dataset such as Vehicle speed, temperature, etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(scaled_df1, y= ['VehicleSpeed', 'BrkVoltage'], title='Time series of braking voltage vs Vehicle Speed')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(scaled_df1, y= ['VehicleSpeed', 'SteerAngle1', 'AccPedal'], title='Time series of acceleration pedal and steering angle vs Vehicle Speed')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** \\\n",
    "Brake Voltage, Acceleration Pedal, and Steering Angle are 3 critical control inputs coming from the human users that determines the speed of the vehicle. We will build the model to predict these control inputs later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df1, \n",
    "              y= ['AirIntakeTemperature', 'AmbientTemperature', 'EngineTemperature', 'OilTemperature1', \n",
    "                  'VehicleSpeed'                          \n",
    "                              ], title='Time series of All temperature related vs Vehicle Speed')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation** \\\n",
    "Temperature measurements are responding to the vehicle speed, however due to the temperature dynamics, the responds exhibit some delays that become hard for controls scheme."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distributions\n",
    "# Numeric variables\n",
    "cols_numeric = df1.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "for col in cols_numeric:\n",
    "    #sns.histplot(df_raw[col], kde=True)\n",
    "    sns.histplot(data =df1, x = col, kde=True) #hue='y', kde=True)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    colname = col.replace(\".\", \"_\")\n",
    "    plt.savefig(f\"results/EDA_{colname}\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling I - Regression model - predict Vehicle Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay , precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression - Feature Engineeering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe data and visualize it\n",
    "corr = df1.corr()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.heatmap(\n",
    "    corr[abs(corr) >=.5], \n",
    "    #corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=\"Reds\",\n",
    "    square=False,\n",
    "    annot=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "\n",
    "plt.title('Correlation among the features that are above 0.7 score')\n",
    "plt.savefig(\"results/EDA_feature_corr\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations** \\\n",
    "There are heavily correlated data between WheelSpeeds (FL, FR, RL, RR) and the torques. It is understandable as the vehicle speed is calculated directed from the linear model with those values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factor check\n",
    "\n",
    "Let's use VIF to methodogically reduce the correlations among the columns.\n",
    "(references: https://en.wikipedia.org/wiki/Variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif(vars, data):\n",
    "    # rules of thumbs if VIF > 5 then there is a strong multi-colinearity among the features\n",
    "    vif_dict ={}\n",
    "    for var in vars:\n",
    "        not_var = [i for i in vars if i !=var]\n",
    "        X, y = data[not_var], data[var]\n",
    "        \n",
    "        r_squared = LinearRegression().fit(X,y).score(X,y)\n",
    "        #calc the VIF\n",
    "        vif = 1/(1-r_squared)\n",
    "        vif_dict[var] = vif\n",
    "\n",
    "    return pd.DataFrame({\"VIF\": vif_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(df1.columns, df1).sort_values(\"VIF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that have VIF scores greater than 5\n",
    "df2 = df1.drop(columns=['Trq_FrictionLoss', 'AirIntakeTemperature',\n",
    "                        'ENG_Trq_ZWR', 'ENG_Trq_DMD', 'OilTemperature1', 'WheelSpeed_RL',  'WheelSpeed_RR', 'WheelSpeed_FL', 'WheelSpeed_FR', 'Trq_Indicated',\n",
    "                        'ENG_Trq_m_ex', 'BoostPressure'\n",
    "                        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df2.corr(), annot = True, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif(df2.columns, df1).sort_values(\"VIF\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\\\n",
    "All VIFs are less than 5, so we are good to go!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression - Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = df2.drop(columns=\"VehicleSpeed\")\n",
    "y = df2[\"VehicleSpeed\"]\n",
    "\n",
    "# Performed the train/test split with 30% test data and random state of 42 for shuffling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the size of the training and testing sets\n",
    "print(\"X_train size:\", X_train.shape)\n",
    "print(\"y_train size:\", y_train.shape)\n",
    "print(\"X_test size:\", X_test.shape)\n",
    "print(\"y_test size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install missing packages\n",
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit # for model CPU performance https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-time\n",
    "import sys\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectFromModel\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import joblib\n",
    "sys.modules['sklearn.externals.joblib'] = joblib # for SFS\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all mse/ mae values for each model\n",
    "df_RegressionModelPerformance  = pd.DataFrame(columns=['model', 'mse', 'r2', 'CPU time'])\n",
    "df_RegressionModelPerformance.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 1: Linear Regresion with all 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_all_features = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "y_pred =  lr_all_features.predict(X_test)\n",
    "lr_mse = mean_squared_error( y_test, y_pred)\n",
    "lr_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "df_RegressionModelPerformance.loc[0] = ['lr_all_features', lr_mse, lr_r2, -1] \n",
    "print(f'LinearRegression_AllFeatures / MSE = {lr_mse}')\n",
    "print(f'LinearRegression_AllFeatures / R2 = {lr_r2}')\n",
    "print(f'LinearRegression_AllFeatures / Coef = {lr_all_features.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(lr_all_features.coef_, index=list(X_train.columns)).sort_values(ascending=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "The LR indicates that Brake Voltage has the most impact of the Vehicle Speed, without other significant measurements! These are quite impressive results!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[0,'CPU time'] = 3.99\n",
    "df_RegressionModelPerformance.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 2: Huber Regression with all 12 features\n",
    "\n",
    "Huber regression with Huber loss is a composite of both MSE and MAE that plays a critical role. A higher loss results in the quadratic equation transforming into a linear equation. If the error is smaller than the cut-off (epsilon), MSE is used. Otherwise, MAE is used. Huber regression handles the outliers judiciously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "huber_all_features = HuberRegressor(fit_intercept=False).fit(X_train, y_train)\n",
    "y_pred =  huber_all_features.predict(X_test)\n",
    "huber_mse = mean_squared_error(y_test, y_pred)\n",
    "huber_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "df_RegressionModelPerformance.loc[1] = ['huber_all_features', huber_mse, huber_r2, -1] \n",
    "print(f'HuberRegression_AllFeatures / MSE = {huber_mse}')\n",
    "print(f'HuberRegression_AllFeatures / R2 = {huber_r2}')\n",
    "print(f'HuberRegression_AllFeatures / Coef = {huber_all_features.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(huber_all_features.coef_, index=list(X_test.columns)).sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[1,'CPU time'] = 274\n",
    "df_RegressionModelPerformance.head(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The Huber Regression gives a comparable prediction and the scores. In Huber, The most impacting feature is the Ambient temperature!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 3: Polynomial Regression 2 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# poly transform\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "lr_poly_all_features = LinearRegression().fit(X_train_poly, y_train)\n",
    "\n",
    "y_pred =  lr_poly_all_features.predict(X_test_poly)\n",
    "poly_mse = mean_squared_error(y_test, y_pred)\n",
    "poly_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "df_RegressionModelPerformance.loc[2] = ['lr_poly_all_features', poly_mse, poly_r2, -1] \n",
    "print(f'PolyRegression_AllFeatures / MSE = {poly_mse}')\n",
    "print(f'PolyRegression_AllFeatures / R2 = {poly_r2}')\n",
    "print(f'PolyRegression_AllFeatures / Coef = {lr_poly_all_features.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[2,'CPU time'] = 19.5\n",
    "df_RegressionModelPerformance.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 4: Sequential Feature Selection with Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sfs_pipe = Pipeline([('poly_features', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                    ('selector', SequentialFeatureSelector(LinearRegression(), n_features_to_select=6)),\n",
    "                    ('linreg', LinearRegression())])\n",
    "sfs_pipe.fit(X_train, y_train)\n",
    "y_pred = sfs_pipe.predict(X_test)\n",
    "sfs_train_mse = mean_squared_error(y_train, sfs_pipe.predict(X_train))\n",
    "sfs_test_mse = mean_squared_error(y_test, y_pred)\n",
    "sfs_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "sfs_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs_coefs = sfs_pipe.named_steps['selector'].coeff_\n",
    "df_RegressionModelPerformance.loc[3] = ['sfs', sfs_test_mse, sfs_r2, -1] \n",
    "sfs_feature_names= sfs_pipe.named_steps['selector'].get_feature_names_out()\n",
    "print(f'SFS / Features = {sfs_feature_names}')\n",
    "print(f'SFS / MSE = {sfs_test_mse}')\n",
    "print(f'SFS / R2 = {sfs_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[3,'CPU time'] = 2_700\n",
    "df_RegressionModelPerformance.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 5: Lasso Regularization with Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lasso_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                      ('scaler', StandardScaler()),\n",
    "                     ('lasso', Lasso(random_state = 42))])\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "y_pred = lasso_pipe.predict(X_test)\n",
    "\n",
    "lasso_coefs = lasso_pipe.named_steps['lasso'].coef_\n",
    "lasso_train_mse = mean_squared_error(y_train, lasso_pipe.predict(X_train))\n",
    "lasso_test_mse = mean_squared_error(y_test, lasso_pipe.predict(X_test))\n",
    "lasso_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "df_RegressionModelPerformance.loc[4] = ['lasso', lasso_test_mse, lasso_r2, -1] \n",
    "lasso_feature_names = lasso_pipe.named_steps['polyfeatures'].get_feature_names_out()\n",
    "print(f'Lasso / Features = {lasso_feature_names}')\n",
    "print(f'Lasso / MSE = {lasso_test_mse}')\n",
    "print(f'Lasso / R2 = {lasso_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[4,'CPU time'] = 103_300\n",
    "df_RegressionModelPerformance.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 6: Ridge regularization with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ridge_param_dict = {'ridge__alpha': np.logspace(0, 10, 50)}\n",
    "ridge_pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                      ('ridge', Ridge())])\n",
    "ridge_grid = GridSearchCV(ridge_pipe, param_grid=ridge_param_dict,scoring = 'neg_root_mean_squared_error')\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "ridge_train_preds = ridge_grid.predict(X_train)\n",
    "ridge_test_preds = ridge_grid.predict(X_test)\n",
    "ridge_train_mse = mean_squared_error(y_train, ridge_train_preds)\n",
    "ridge_test_mse = mean_squared_error(y_test, ridge_test_preds)\n",
    "ridge_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "ridge_pipe\n",
    "\n",
    "df_RegressionModelPerformance.loc[5] = ['ridge', ridge_test_mse, ridge_r2, -1] \n",
    "print(f'Ridge / MSE = {ridge_test_mse}')\n",
    "print(f'Ridge / R2 = {ridge_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[5,'CPU time'] = 1_520\n",
    "df_RegressionModelPerformance.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 7: Ridge and Transformed Target Regressor with GridSearchCV\n",
    "\n",
    "As recall from the Price plot distribution, the Price is not normally distributed and let's try using the transform target regressor to help improve the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ttr = TransformedTargetRegressor(regressor = Ridge(), transformer=MinMaxScaler())\n",
    "ss = MinMaxScaler()\n",
    "\n",
    "ridge_tts_pipe = Pipeline([('polyfeatures', PolynomialFeatures(degree = 2, include_bias = False)),\n",
    "                 ('ttregressor', ttr)])\n",
    "\n",
    "ridge_tts_pipe.fit(X_train, y_train)\n",
    "ridge_tts_pipe.score(X_test, y_test)\n",
    "\n",
    "param_grid_ridge_tts = {'ttregressor__regressor__alpha':[True,False]}\n",
    "grid_ridge_tts = GridSearchCV(ridge_tts_pipe,param_grid=param_grid_ridge_tts, cv=None)\n",
    "grid_ridge_tts.fit(X_train, y_train)\n",
    "print(\"best alpha: \", grid_ridge_tts.best_score_)\n",
    "\n",
    "ridge_tts_train_preds = grid_ridge_tts.predict(X_train)\n",
    "ridge_tts_test_preds = grid_ridge_tts.predict(X_test)\n",
    "ridge_tts_train_mse = mean_squared_error(y_train, ridge_tts_train_preds)\n",
    "ridge_tts_test_mse = mean_squared_error(y_test, ridge_tts_test_preds)\n",
    "ridge_tts_r2 = r2_score(y_test, ridge_tts_test_preds)\n",
    "\n",
    "ridge_tts_pipe\n",
    "\n",
    "df_RegressionModelPerformance.loc[6] = ['ridge_tts', ridge_tts_test_mse, ridge_tts_r2, -1] \n",
    "print(f'Ridge / MSE = {ridge_tts_test_mse}')\n",
    "print(f'Ridge / R2 = {ridge_tts_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually record CPU time\n",
    "df_RegressionModelPerformance.loc[6,'CPU time'] = 272\n",
    "df_RegressionModelPerformance.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Model 9: Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2128\\2498276925.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Bring in subpackages.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# from tensorflow.python import keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    417\u001b[0m \"\"\"\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_autograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnested_structure_coder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_checkpoint_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(50, activation = 'relu'))\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "model1.compile(loss = 'bce', metrics = ['acc'])\n",
    "history1 = model1.fit(X_train, y_train, validation_data = (X_test, y_test),\n",
    "                     epochs = 10, verbose = 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling II - Classifiers - detect Controls Inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers - Classify the Controls Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =[]\n",
    "df3 = df2\n",
    "df3.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize the Brake Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['BrkVoltage'] = df3['BrkVoltage'].astype(int)\n",
    "df3['BrkVoltage']\n",
    "fig = px.line(df3['BrkVoltage'], title='Time series of Vehicle CAN data - Brake Voltage')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify the Steering Angles** \\\n",
    "Calculate the diffference in time series of the Steer angles:\n",
    "* if the difference >0 then its a turn left input, \n",
    "* else it is a turn right input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =df3.drop(columns= 'SteerAngle1')\n",
    "df3['inpSteerDirection'] = df2['SteerAngle1'].diff().fillna(0)\n",
    "\n",
    "# < 0 is turn left, > 0 is turn right\n",
    "bins = [-1000, 0, 1000]\n",
    "group_names = [ 'Left', 'Right'] \n",
    "df3['inpSteerDirection'] = pd.cut(df3['inpSteerDirection'], bins, labels=group_names)\n",
    "\n",
    "fig = px.line(df3[['inpSteerDirection']], title='Time series of Vehicle CAN data - inpSteerDirection')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify the Acceleration Pedal** \\\n",
    "Calculate the diffference in time series of the Acceleration Pedal:\n",
    "* if the difference > 0 then the pedal is pressed, \n",
    "* else it is no pedal press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =df3.drop(columns= 'AccPedal')\n",
    "df3['inpAccPedal'] = df2['AccPedal'].diff().fillna(0)\n",
    "\n",
    "# < 0 is turn left, > 0 is turn right\n",
    "bins = [-1000, 0, 1000]\n",
    "group_names = [ 0, 1] \n",
    "df3['inpAccPedal'] = pd.cut(df3['inpAccPedal'], bins, labels=group_names)\n",
    "\n",
    "fig = px.line(df3[['inpAccPedal']], title='Time series of Vehicle CAN data - AccPedal_inp')\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers - Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical columns\n",
    "cols_le = [\"inpSteerDirection\", 'inpAccPedal']\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "encoded_le_df = df3[cols_le].apply(le.fit_transform)\n",
    "\n",
    "# Combine encoded categorical variables with the original dataframe\n",
    "df_encoded =[]\n",
    "df_encoded = df3.drop(columns=cols_le)\n",
    "df_encoded = pd.concat([df_encoded, encoded_le_df], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers- Train/ Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "#cols = [\"inpSteerDirection\", \"BrkVoltage\",\"inpAccPedal\" ]\n",
    "cols = [\"BrkVoltage\"]\n",
    "X = df_encoded.drop(columns=cols)\n",
    "y = df_encoded[cols]\n",
    "\n",
    "# Performed the train/test split with 30% test data and random state of 42 for shuffling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the size of the training and testing sets\n",
    "print(\"X_train size:\", X_train.shape)\n",
    "print(\"y_train size:\", y_train.shape)\n",
    "print(\"X_test size:\", X_test.shape)\n",
    "print(\"y_test size:\", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier - A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a dummy classifier that always predicts the majority class\n",
    "strategies = ['most_frequent', 'stratified', 'uniform']\n",
    "  \n",
    "test_scores = []\n",
    "\n",
    "for s in strategies:\n",
    "    \n",
    "    dummy = DummyClassifier(strategy = s)\n",
    "  \n",
    "    # Fit the classifier on the training data\n",
    "    dummy.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the classifier on the data\n",
    "    accuracy_train = dummy.score(X_train, y_train)\n",
    "    accuracy_test = dummy.score(X_test, y_test)\n",
    "    # Print the baseline accuracy\n",
    "    print(f\"Strategy {s} --- Baseline accuracy train: {accuracy_train} --- Baseline accuracy test: {accuracy_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Model 1 - A simple model \n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Configure the search space \n",
    "logreg_params = {'solver': ['liblinear', 'lbfgs'], 'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100], 'class_weight': [None, 'balanced']}\n",
    "logreg_model=\"\"\n",
    "\n",
    "# Grid search CV for Logistic Regression\n",
    "logreg_model = GridSearchCV(LogisticRegression(), logreg_params, cv=5)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "logreg_best_params = logreg_model.best_params_\n",
    "print(f\"Logistic Regression best param: {logreg_best_params}\")\n",
    "\n",
    "# score the logistic regression model on the data\n",
    "train_accuracy = logreg_model.score(X_train, y_train)\n",
    "test_accuracy = logreg_model.score(X_test, y_test)\n",
    "# Print the train  accuracy\n",
    "print(\"Logistic Regression accuracy train: {:.5f}\".format(train_accuracy))\n",
    "print(\"Logistic Regression accuracy test: {:.5f}\".format(test_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy of the model\n",
    "print(\"Accuracy train: {:.5f}\".format(train_accuracy))\n",
    "print(\"Accuracy test: {:.5f}\".format(test_accuracy))\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Calculate the precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1 Score: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a confusion matrix display\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=logreg_model.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cmd.plot(cmap= \"Paired\")\n",
    "plt.title('Confusion Matrix for Logistic Regression model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the ROC curve\n",
    "\n",
    "y_score = logreg_model.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score, pos_label=logreg_model.classes_[1])\n",
    "roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "plt.title('Roc Curve Display for Logistic Regression model')\n",
    "\n",
    "auc_score =roc_auc_score(y_test, logreg_model.predict_proba(X_test)[:,1])\n",
    "print(\"Roc AUC Score: {:.5f}\".format(auc_score))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the performance\n",
    "df_performance = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params for GridSearchCV\n",
    "dec_tree_params = {'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50], 'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "knn_params = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'algorithm': ['auto', 'ball_tree', 'kd_tree'], 'leaf_size': [20, 30, 40]}\n",
    "svm_params = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3], 'gamma': ['scale', 'auto'], 'class_weight': [None, 'balanced']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!! Precautions, the next cell can take 3 minutes to execute !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch for Decision Tree\n",
    "dec_tree_grid = GridSearchCV(DecisionTreeClassifier(), dec_tree_params, cv=5)\n",
    "dec_tree_grid.fit(X_train, y_train)\n",
    "dec_tree_best_params = dec_tree_grid.best_params_\n",
    "print(\"Decision Tree best params:\", dec_tree_grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!! Precautions, the next cell can take 5 minutes to execute !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5)\n",
    "knn_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_params = knn_grid.best_params_\n",
    "print(\"KNN best params:\", knn_grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### !!! Precautions, the next cell can take up to 10 hours to execute !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch for SVM\n",
    "svm_grid = GridSearchCV(SVC(), svm_params, cv=5)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "svm_best_params = svm_grid.best_params_\n",
    "print(\"SVM best params:\", svm_grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "From the GridSearch, we are able to identify the best params for each model as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "# Logistic Regression best param: {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "log_reg_params = {'C': 10, 'class_weight': None, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "# Decision Tree best params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n",
    "dec_tree_params = {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 0.1}\n",
    "# KNN best params: {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 7, 'weights': 'distance'}\n",
    "knn_params = {'algorithm': 'auto', 'leaf_size': 20, 'n_neighbors': 7, 'weights': 'distance'}\n",
    "svm_params = {'C': 1.0, 'class_weight': 'balanced', 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the models\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(**log_reg_params),\n",
    "    \"Decision Trees\": DecisionTreeClassifier(**dec_tree_params),\n",
    "    \"KNN\": KNeighborsClassifier(**knn_params),\n",
    "    \"SVM\": SVC(**svm_params)\n",
    "}\n",
    "\n",
    "# Custom function to evaluate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return {\"Test Accuracy\": accuracy, \"Test f1\": f1, \"Test Precision\": precision, \"Test Recall\": recall}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "metrics = {}\n",
    "df_metrics = []\n",
    "df_performance = []\n",
    "df_performance = pd.DataFrame(columns=['Model', 'Train Time', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "for model, clf in classifiers.items():\n",
    "    # Train the model and capture execution time\n",
    "    start_time = time.time()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "\n",
    "    # Accuracy on train and test data\n",
    "    train_accuracy = clf.score(X_train, y_train)\n",
    "    test_accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    # model performance\n",
    "    df_model_performance = pd.DataFrame({'Model': [model], 'Train Time': [train_time], 'Train Accuracy': [train_accuracy], 'Test Accuracy': [test_accuracy]})\n",
    "\n",
    "    # Compute all other metrics\n",
    "    y_pred = clf.predict(X_test)\n",
    "    metrics[model] = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Store the performance\n",
    "    df_performance = pd.concat([df_performance, df_model_performance], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics).T\n",
    "df_metrics.reset_index(inplace=True)\n",
    "df_metrics = df_metrics.rename(columns = {'index':'Model'})\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "df_results = pd.merge(df_performance, df_metrics)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_metrics(df_results):\n",
    "    # Visualize bar plots for all metrics\n",
    "    cmap = plt.get_cmap('Set2')\n",
    "    colors = [cmap(i) for i in range(len(df_results.columns))]    \n",
    "    ax = df_results.loc[:, df_results.columns != \"Train Time\"].plot.bar(rot=0, color = colors)\n",
    "\n",
    "    # Set labels\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Accuracy Scores')\n",
    "    bar_positions = np.arange(len(df_results))\n",
    "    plt.xticks(bar_positions, df_results[\"Model\"], rotation=90)\n",
    "    plt.title('Comparison of Model Performance')\n",
    "\n",
    "    # Visualize the 'Train Time' on top of the 'Train Accuracy' bar\n",
    "    for idx, value in enumerate(df_results['Train Time']):\n",
    "        ax.text(idx - 0.15, df_results['Train Accuracy'][idx] + 0.015, f'[{value:.2f}sec]', fontsize=9)\n",
    "\n",
    "    # Display the legend outside the plot area\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.2))\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_metrics(df_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling III - Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from warnings import filterwarnings \n",
    "filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa import arima_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = arima_process.ArmaProcess(ar = [.9, -.3], ma = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'VehicleSpeed'\n",
    "df_DUT = df1[[col_name]]\n",
    "#df_DUT = df_DUT.set_index(pd.to_datetime(df_DUT.index)) \\\n",
    "#    .drop(columns=['Unnamed: 0','Date']) \\\n",
    "#    .rename('values')\n",
    "df_DUT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_DUT)\n",
    "plt.title('Vehicle Speed', loc = 'left')\n",
    "plt.grid();\n",
    "### Build historical dataset\n",
    "y_hist = df_DUT[:7000]\n",
    "y_future = df_DUT[7001:]\n",
    "\n",
    "print('Historical:')\n",
    "print(y_hist.tail())\n",
    "print('=========\\nFuture:')\n",
    "print(y_future.head())\n",
    "plt.plot(y_hist, label = 'historical')\n",
    "plt.plot(y_future, label = 'future')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our exercise, we will use a built in estimator from statsmodels -- the `STL` model.  To use this model, create an instance of the `STL` estimator and pass `y_hist` and a period value of 12.  \n",
    "\n",
    "Use the `stl` instance to fit the model, assigning the fit results to `results` below.  This results object will contain the trend as an attribute.  Uncomment the code to see the trend plotted with the original data after fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "import statsmodels.graphics.tsaplots as tsplots\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.tsa.forecasting.stl import STLForecast\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "stl = STL(y_hist, period = 20)\n",
    "results = stl.fit()\n",
    "plt.plot(results.trend)\n",
    "plt.plot(y_hist)\n",
    "plt.title('Trend with CO2 Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_and_trend = results.seasonal + results.trend\n",
    "### END SOLUTION\n",
    "\n",
    "## Answer Check\n",
    "plt.plot(season_and_trend, label = 'seasonal + trend')\n",
    "plt.plot(y_hist, label = 'actual')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARMA Process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.filters.filtertools import convolution_filter\n",
    "import statsmodels.graphics.tsaplots as tsaplots\n",
    "from statsmodels.tsa.seasonal import _extrapolate_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 1000\n",
    "\n",
    "\n",
    "filt = np.ones(period+1)\n",
    "filt[0] = 0.5\n",
    "filt[-1] = 0.5\n",
    "filt /= period\n",
    "\n",
    "sum(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = convolution_filter(y_hist, filt)\n",
    "trend = _extrapolate_trend(trend, period + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
